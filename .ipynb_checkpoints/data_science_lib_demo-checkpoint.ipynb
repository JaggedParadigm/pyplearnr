{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Library demo\n",
    "Here I demonstrate the data science library I developed to quickly build scikit learn pipelines with optional scaling, feature interaction, data transformation (e.g. PCA, t-SNE) steps. It runs the pipeline through a grid-search (all combinations or a specific number of them) stratified (if classification) k-folds cross-validation and outputs the best model.\n",
    "\n",
    "## Titanic dataset\n",
    "Here I use the Titanic dataset I've cleaned and pickled in a separate tutorial.\n",
    "\n",
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "Title       891 non-null object\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('trimmed_titanic_data.pkl')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By \"cleaned\" I mean I've derived titles (e.g. \"Mr.\", \"Mrs.\", \"Dr.\", etc) from the passenger names, imputed the missing Age values using polynomial regression with grid-searched 10-fold cross-validation, filled in the 3 missing Embarked values with the mode, and removed all fields that could be considered an id for that individual.\n",
    "\n",
    "Thus, there is no missing data.\n",
    "\n",
    "## One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "Survived          891 non-null int64\n",
      "Pclass            891 non-null int64\n",
      "Age               891 non-null float64\n",
      "SibSp             891 non-null int64\n",
      "Parch             891 non-null int64\n",
      "Fare              891 non-null float64\n",
      "Sex_male          891 non-null uint8\n",
      "Embarked_Q        891 non-null uint8\n",
      "Embarked_S        891 non-null uint8\n",
      "Title_Dr          891 non-null uint8\n",
      "Title_Military    891 non-null uint8\n",
      "Title_Miss        891 non-null uint8\n",
      "Title_Mr          891 non-null uint8\n",
      "Title_Mrs         891 non-null uint8\n",
      "Title_Noble       891 non-null uint8\n",
      "Title_Rev         891 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(10)\n",
      "memory usage: 50.5 KB\n"
     ]
    }
   ],
   "source": [
    "simulation_df = df.copy()\n",
    "\n",
    "simulation_df = pd.get_dummies(simulation_df,drop_first=True)\n",
    "\n",
    "simulation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 16 features.\n",
    "\n",
    "### Split into input/output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set output feature\n",
    "output_feature = 'Survived'\n",
    "\n",
    "# Get all column names\n",
    "column_names = list(simulation_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = simulation_df[input_features].copy()\n",
    "y = simulation_df[output_feature].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61616162,  0.38383838])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df['Survived'].value_counts().values/float(simulation_df['Survived'].value_counts().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, null accuracy of ~62% if always predict death.\n",
    "\n",
    "### Import data science library and initialize model collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import data_science_lib as dsl\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic models w/ no pre-processing\n",
    "#### KNN\n",
    "Here I do a simple K-nearest neighbors (KNN) classification with 10-fold (default) cross-validation with a grid search over the default of 1 to 30 nearest neighbors and the use of either \"uniform\" or \"distance\" weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.731741573034\n",
      "\n",
      "Test set classification accuracy:  0.748603351955\n",
      "Confusion matrix: \n",
      "\n",
      " [[96 17]\n",
      " [28 38]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53631285  0.09497207]\n",
      " [ 0.15642458  0.2122905 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81       113\n",
      "          1       0.69      0.58      0.63        66\n",
      "\n",
      "avg / total       0.74      0.75      0.74       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 30, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=30, p=2,\n",
      "           weights='distance'))])\n",
      "CPU times: user 1.78 s, sys: 133 ms, total: 1.91 s\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "        \n",
    "# Figure out best model\n",
    "models['knn'] = dsl.train_model(X,y,\n",
    "                                use_default_param_dist=True,\n",
    "                                random_state=6,\n",
    "                                suppress_output=False, # Can suppress print outs if desired\n",
    "                                estimator='knn',) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that the best settings are 30 neighbors and the use of the 'distance' weight.\n",
    "\n",
    "Note how I've set the random_state to 6 so that the models can be compared using the same test/train split.\n",
    "\n",
    "The output of the train_model() method is a Pipeline object with the optimal parameters found during the grid search and trained on all data.\n",
    "\n",
    "Additional fields have been added to the pipeline object. These extra parameters are the type of score ('regression' or 'classification'), '.score_type', the training score (L2 norm for regression and classification accuracy for classification), '.train_score', the corresponding test score, '.test_score'. \n",
    "\n",
    "For classification problems, additional parameters also include the confusion matrix, '.confusion_matrix', normalized confusion matrix, '.normalized_confusion_matrix', and the classification report, '.classification_report'.\n",
    "\n",
    "Here are the outputs of these additional parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "0.731741573034\n",
      "0.748603351955\n",
      "{'estimator__n_neighbors': 30, 'estimator__weights': 'distance'}\n",
      "[[96 17]\n",
      " [28 38]]\n",
      "[[ 0.53631285  0.09497207]\n",
      " [ 0.15642458  0.2122905 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81       113\n",
      "          1       0.69      0.58      0.63        66\n",
      "\n",
      "avg / total       0.74      0.75      0.74       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = models['knn']\n",
    "\n",
    "# Score type and training/test scores\n",
    "print(pipeline.score_type)\n",
    "\n",
    "print(pipeline.train_score)\n",
    "\n",
    "print(pipeline.test_score)\n",
    "\n",
    "# Best parameters\n",
    "print(pipeline.best_parameters)\n",
    "\n",
    "# Confusion matrix, if classification\n",
    "print(pipeline.confusion_matrix) \n",
    "\n",
    "# Confusion matrix divided by its total sum\n",
    "print(pipeline.normalized_confusion_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(pipeline.classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print out from the solution above indicates that the default parameters to grid over are n_neighbors from 1 to 30 and the weights parameter as either 'uniform' or 'distance'.\n",
    "\n",
    "This can be changed in two different ways. One way is to overwrite the parameter values by setting the param_dist keyword argument with the use_default_param_dist set to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.741573033708\n",
      "\n",
      "Test set classification accuracy:  0.759776536313\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 30  36]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.16759777  0.20111732]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.88      0.82       113\n",
      "          1       0.73      0.55      0.63        66\n",
      "\n",
      "avg / total       0.76      0.76      0.75       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 74, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=74, p=2,\n",
      "           weights='distance'))])\n",
      "CPU times: user 31.3 s, sys: 1.12 s, total: 32.4 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set custom parameters\n",
    "param_dist = {\n",
    "    'estimator__n_neighbors': range(30,500)\n",
    "}\n",
    "\n",
    "# Figure out best model\n",
    "models['custom_overwrite_knn'] = dsl.train_model(X,y,\n",
    "                                       use_default_param_dist=True,\n",
    "                                       random_state=6,\n",
    "                                       suppress_output=False, # Can suppress print outs if desired\n",
    "                                       estimator='knn',\n",
    "                                       param_dist = param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to get a slightly better accuracy doing this.\n",
    "\n",
    "The second way to use different parameter grid values is to set them with the custom param_dist keyword argument yet set use_default_param_dist to False. This makes it so that you must set every single parameter manually.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "\n",
      "Training set classification accuracy:  0.712078651685\n",
      "\n",
      "Test set classification accuracy:  0.703910614525\n",
      "Confusion matrix: \n",
      "\n",
      " [[96 17]\n",
      " [36 30]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53631285  0.09497207]\n",
      " [ 0.20111732  0.16759777]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78       113\n",
      "          1       0.64      0.45      0.53        66\n",
      "\n",
      "avg / total       0.69      0.70      0.69       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 34}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=34, p=2,\n",
      "           weights='uniform'))])\n",
      "CPU times: user 15.1 s, sys: 580 ms, total: 15.6 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set custom parameters\n",
    "param_dist = {\n",
    "    'estimator__n_neighbors': range(30,500)\n",
    "}\n",
    "\n",
    "# Figure out best model\n",
    "models['from_scratch_knn'] = dsl.train_model(X,y,\n",
    "                                       use_default_param_dist=False,\n",
    "                                       random_state=6,\n",
    "                                       suppress_output=False, # Can suppress print outs if desired\n",
    "                                       estimator='knn',\n",
    "                                       param_dist = param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the estimator__weights parameter isn't set for the KNN estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other models\n",
    "This code currently supports K-nearest neighbors, logistic regression, support vector machines, multilayer perceptrons, random forest, and adaboost. \n",
    "\n",
    "We can loop through and pick the best model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.731741573034\n",
      "\n",
      "Test set classification accuracy:  0.748603351955\n",
      "Confusion matrix: \n",
      "\n",
      " [[96 17]\n",
      " [28 38]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53631285  0.09497207]\n",
      " [ 0.15642458  0.2122905 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81       113\n",
      "          1       0.69      0.58      0.63        66\n",
      "\n",
      "avg / total       0.74      0.75      0.74       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 30, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=30, p=2,\n",
      "           weights='distance'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.820224719101\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.720505617978\n",
      "\n",
      "Test set classification accuracy:  0.782122905028\n",
      "Confusion matrix: \n",
      "\n",
      " [[96 17]\n",
      " [22 44]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53631285  0.09497207]\n",
      " [ 0.12290503  0.24581006]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       113\n",
      "          1       0.72      0.67      0.69        66\n",
      "\n",
      "avg / total       0.78      0.78      0.78       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.811797752809\n",
      "\n",
      "Test set classification accuracy:  0.837988826816\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.88       113\n",
      "          1       0.82      0.71      0.76        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [9]}\n",
      "\n",
      " Pipeline(steps=[('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=[9], learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.825842696629\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 14  52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       113\n",
      "          1       0.80      0.79      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 94}\n",
      "\n",
      " Pipeline(steps=[('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=94, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.794943820225\n",
      "\n",
      "Test set classification accuracy:  0.860335195531\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       113\n",
      "          1       0.85      0.76      0.80        66\n",
      "\n",
      "avg / total       0.86      0.86      0.86       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 6.23 s, sys: 517 ms, total: 6.74 s\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models[model_name] = dsl.train_model(X,y,\n",
    "                                    use_default_param_dist=True,\n",
    "                                    random_state=6,\n",
    "                                    estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the best model is logistic regression with a classfication accuracy of ~88%.\n",
    "\n",
    "### Scaled data then classification\n",
    "We can specify the scale_type keyword argument to scale the data before being fed to the desired estimator. Currently only standard scaling is supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.832865168539\n",
      "\n",
      "Test set classification accuracy:  0.821229050279\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.88      0.86       113\n",
      "          1       0.78      0.71      0.75        66\n",
      "\n",
      "avg / total       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 7, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.820224719101\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.813202247191\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89       113\n",
      "          1       0.88      0.68      0.77        66\n",
      "\n",
      "avg / total       0.85      0.85      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.830056179775\n",
      "\n",
      "Test set classification accuracy:  0.826815642458\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 22  44]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.12290503  0.24581006]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87       113\n",
      "          1       0.83      0.67      0.74        66\n",
      "\n",
      "avg / total       0.83      0.83      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [3]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=[3], learning_rate='constant',\n",
      "       learning_r...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.823033707865\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 14  52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       113\n",
      "          1       0.80      0.79      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 93}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=93, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.794943820225\n",
      "\n",
      "Test set classification accuracy:  0.860335195531\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       113\n",
      "          1       0.85      0.76      0.80        66\n",
      "\n",
      "avg / total       0.86      0.86      0.86       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 6.72 s, sys: 576 ms, total: 7.3 s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_%s'%(model_name)] = dsl.train_model(X,y,\n",
    "                                                       use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection, scaling, and classification\n",
    "The feature_selection_type keyword argument can be used to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.835674157303\n",
      "\n",
      "Test set classification accuracy:  0.832402234637\n",
      "Confusion matrix: \n",
      "\n",
      " [[102  11]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.5698324   0.06145251]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       113\n",
      "          1       0.81      0.71      0.76        66\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 7, 'feature_selection__k': 12, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=12, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.820224719101\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 15, 'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=15, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89       113\n",
      "          1       0.88      0.68      0.77        66\n",
      "\n",
      "avg / total       0.85      0.85      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 13}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=13, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.827247191011\n",
      "\n",
      "Test set classification accuracy:  0.810055865922\n",
      "Confusion matrix: \n",
      "\n",
      " [[99 14]\n",
      " [20 46]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55307263  0.07821229]\n",
      " [ 0.11173184  0.25698324]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85       113\n",
      "          1       0.77      0.70      0.73        66\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 9, 'estimator__hidden_layer_sizes': [12]}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=9, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, ...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.823033707865\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 14  52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       113\n",
      "          1       0.80      0.79      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 15, 'estimator__n_estimators': 92}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=15, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='a...imators=92, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Training set classification accuracy:  0.803370786517\n",
      "\n",
      "Test set classification accuracy:  0.843575418994\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 18  48]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.10055866  0.26815642]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88       113\n",
      "          1       0.83      0.73      0.77        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 11}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=11, score_func=<function f_classif at 0x10e09b7d0>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 1min 20s, sys: 5.05 s, total: 1min 25s\n",
      "Wall time: 9min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['select_scaled_%s'%(model_name)] = dsl.train_model(X,y,\n",
    "                                                       use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       feature_selection_type = 'select_k_best', \n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that logistic regression without scaling outperforms all combinations of scalling and the classifiers.\n",
    "\n",
    "### Scaled, transformed, then classification\n",
    "Setting the transform_type keyword argument allows the data to be transformed into a new coordinate system that is dependent on the algorithm.\n",
    "\n",
    "Currently, only principal component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE) are supported.\n",
    "\n",
    "#### PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.832865168539\n",
      "\n",
      "Test set classification accuracy:  0.821229050279\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.88      0.86       113\n",
      "          1       0.78      0.71      0.75        66\n",
      "\n",
      "avg / total       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 7, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.820224719101\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.813202247191\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89       113\n",
      "          1       0.88      0.68      0.77        66\n",
      "\n",
      "avg / total       0.85      0.85      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.832865168539\n",
      "\n",
      "Test set classification accuracy:  0.843575418994\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.88       113\n",
      "          1       0.84      0.71      0.77        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [5]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.801966292135\n",
      "\n",
      "Test set classification accuracy:  0.826815642458\n",
      "Confusion matrix: \n",
      "\n",
      " [[96 17]\n",
      " [14 52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53631285  0.09497207]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86       113\n",
      "          1       0.75      0.79      0.77        66\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 93}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini...imators=93, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.807584269663\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89       113\n",
      "          1       0.83      0.76      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 10.6 s, sys: 775 ms, total: 11.4 s\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_pca_%s'%(model_name)] = dsl.train_model(X,y,use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                        transform_type='pca',\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_scaled_logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score,'\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation with PCA doesn't appear to improve our results so far.\n",
    "\n",
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.566011235955\n",
      "\n",
      "Test set classification accuracy:  0.63687150838\n",
      "Confusion matrix: \n",
      "\n",
      " [[97 16]\n",
      " [49 17]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.54189944  0.08938547]\n",
      " [ 0.27374302  0.09497207]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.86      0.75       113\n",
      "          1       0.52      0.26      0.34        66\n",
      "\n",
      "avg / total       0.61      0.64      0.60       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 4, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...owski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.540730337079\n",
      "\n",
      "Test set classification accuracy:  0.659217877095\n",
      "Confusion matrix: \n",
      "\n",
      " [[72 41]\n",
      " [20 46]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.40223464  0.22905028]\n",
      " [ 0.11173184  0.25698324]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.64      0.70       113\n",
      "          1       0.53      0.70      0.60        66\n",
      "\n",
      "avg / total       0.69      0.66      0.67       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 1e-10}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.608146067416\n",
      "\n",
      "Test set classification accuracy:  0.642458100559\n",
      "Confusion matrix: \n",
      "\n",
      " [[113   0]\n",
      " [ 64   2]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.63128492  0.        ]\n",
      " [ 0.3575419   0.01117318]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78       113\n",
      "          1       1.00      0.03      0.06        66\n",
      "\n",
      "avg / total       0.77      0.64      0.51       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.547752808989\n",
      "\n",
      "Test set classification accuracy:  0.692737430168\n",
      "Confusion matrix: \n",
      "\n",
      " [[82 31]\n",
      " [24 42]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.45810056  0.17318436]\n",
      " [ 0.13407821  0.23463687]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.73      0.75       113\n",
      "          1       0.58      0.64      0.60        66\n",
      "\n",
      "avg / total       0.70      0.69      0.70       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [12]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.558988764045\n",
      "\n",
      "Test set classification accuracy:  0.664804469274\n",
      "Confusion matrix: \n",
      "\n",
      " [[74 39]\n",
      " [21 45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.41340782  0.21787709]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.65      0.71       113\n",
      "          1       0.54      0.68      0.60        66\n",
      "\n",
      "avg / total       0.69      0.66      0.67       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 99}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...imators=99, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.532303370787\n",
      "\n",
      "Test set classification accuracy:  0.558659217877\n",
      "Confusion matrix: \n",
      "\n",
      " [[59 54]\n",
      " [25 41]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.32960894  0.30167598]\n",
      " [ 0.1396648   0.22905028]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.52      0.60       113\n",
      "          1       0.43      0.62      0.51        66\n",
      "\n",
      "avg / total       0.60      0.56      0.57       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...m='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 1min 10s, sys: 5.95 s, total: 1min 16s\n",
      "Wall time: 24min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_t-sne_%s'%(model_name)] = dsl.train_model(X,y,use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                        transform_type='t-sne',\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_scaled_logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score,'\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with with scaling and selection appears to outperform all other scenarios so far."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
