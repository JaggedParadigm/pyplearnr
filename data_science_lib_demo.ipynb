{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this Jupyter notebook is to demonstrate my data science library.\n",
    "\n",
    "I'm going to use the Titanic dataset so the first section is about preparing the data for visualization/analysis.\n",
    "\n",
    "# Prepare/clean data\n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive title from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Braund, Mr. Owen Harris\n",
       "1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
       "2                                 Heikkinen, Miss. Laina\n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "4                               Allen, Mr. William Henry\n",
       "5                                       Moran, Mr. James\n",
       "6                                McCarthy, Mr. Timothy J\n",
       "7                         Palsson, Master. Gosta Leonard\n",
       "8      Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\n",
       "9                    Nasser, Mrs. Nicholas (Adele Achem)\n",
       "10                       Sandstrom, Miss. Marguerite Rut\n",
       "11                              Bonnell, Miss. Elizabeth\n",
       "12                        Saundercock, Mr. William Henry\n",
       "13                           Andersson, Mr. Anders Johan\n",
       "14                  Vestrom, Miss. Hulda Amanda Adolfina\n",
       "15                      Hewlett, Mrs. (Mary D Kingcome) \n",
       "16                                  Rice, Master. Eugene\n",
       "17                          Williams, Mr. Charles Eugene\n",
       "18     Vander Planke, Mrs. Julius (Emelia Maria Vande...\n",
       "19                               Masselmani, Mrs. Fatima\n",
       "20                                  Fynney, Mr. Joseph J\n",
       "21                                 Beesley, Mr. Lawrence\n",
       "22                           McGowan, Miss. Anna \"Annie\"\n",
       "23                          Sloper, Mr. William Thompson\n",
       "24                         Palsson, Miss. Torborg Danira\n",
       "25     Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...\n",
       "26                               Emir, Mr. Farred Chehab\n",
       "27                        Fortune, Mr. Charles Alexander\n",
       "28                         O'Dwyer, Miss. Ellen \"Nellie\"\n",
       "29                                   Todoroff, Mr. Lalio\n",
       "                             ...                        \n",
       "861                          Giles, Mr. Frederick Edward\n",
       "862    Swift, Mrs. Frederick Joel (Margaret Welles Ba...\n",
       "863                    Sage, Miss. Dorothy Edith \"Dolly\"\n",
       "864                               Gill, Mr. John William\n",
       "865                             Bystrom, Mrs. (Karolina)\n",
       "866                         Duran y More, Miss. Asuncion\n",
       "867                 Roebling, Mr. Washington Augustus II\n",
       "868                          van Melkebeke, Mr. Philemon\n",
       "869                      Johnson, Master. Harold Theodor\n",
       "870                                    Balkic, Mr. Cerin\n",
       "871     Beckwith, Mrs. Richard Leonard (Sallie Monypeny)\n",
       "872                             Carlsson, Mr. Frans Olof\n",
       "873                          Vander Cruyssen, Mr. Victor\n",
       "874                Abelson, Mrs. Samuel (Hannah Wizosky)\n",
       "875                     Najib, Miss. Adele Kiamie \"Jane\"\n",
       "876                        Gustafsson, Mr. Alfred Ossian\n",
       "877                                 Petroff, Mr. Nedelio\n",
       "878                                   Laleff, Mr. Kristo\n",
       "879        Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)\n",
       "880         Shelley, Mrs. William (Imanita Parrish Hall)\n",
       "881                                   Markun, Mr. Johann\n",
       "882                         Dahlberg, Miss. Gerda Ulrika\n",
       "883                        Banfield, Mr. Frederick James\n",
       "884                               Sutehall, Mr. Henry Jr\n",
       "885                 Rice, Mrs. William (Margaret Norton)\n",
       "886                                Montvila, Rev. Juozas\n",
       "887                         Graham, Miss. Margaret Edith\n",
       "888             Johnston, Miss. Catherine Helen \"Carrie\"\n",
       "889                                Behr, Mr. Karl Howell\n",
       "890                                  Dooley, Mr. Patrick\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          517\n",
       "Miss        186\n",
       "Mrs         125\n",
       "Child        40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Military      5\n",
       "Noble         5\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_map = {'Mr': 'Mr',\n",
    "'Miss': 'Miss',\n",
    "'Mrs': 'Mrs',\n",
    "'Master': 'Child',\n",
    "'Dr': 'Dr',\n",
    "'Don': 'Noble',\n",
    "'Rev': 'Rev',\n",
    "'Ms': 'Miss',\n",
    "'Mme': 'Miss',\n",
    "'Major': 'Military',\n",
    "'Col': 'Military',\n",
    "'Capt': 'Military',\n",
    "'the Countess': 'Noble',\n",
    "'Major': 'Military',\n",
    "'Mlle': 'Miss', \n",
    "'Jonkheer': 'Noble',\n",
    "'Lady': 'Noble',\n",
    "'Sir': 'Noble'} \n",
    "\n",
    "df['Title'] = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "df['Title'] = df.Title.map(title_map)\n",
    "\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is missing Age, Cabin, and Embarked data. \n",
    "\n",
    "There is so much missing Cabin data it should probably just be discarded.\n",
    "\n",
    "Let's look at the distribution for Embarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "S    0.724409\n",
      "C    0.188976\n",
      "Q    0.086614\n",
      "Name: Embarked, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['Embarked'].value_counts()\n",
    "print df['Embarked'].value_counts()/df['Embarked'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is such a high percentage of S cabins and only 3 entries don't have this data filling the blanks with S (highest frequency) is probably rather good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Embarked'].fillna('S',inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the 'Age' data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11503dd50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEeCAYAAACZlyICAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZKf8fc88SH8JIpCoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11439f910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain median Age\n",
    "median_age = df['Age'].median()\n",
    "\n",
    "# Plot a quick histogram of it:\n",
    "df['Age'].plot.hist(bins=15,color='r')\n",
    "\n",
    "# Set title\n",
    "plt.title('Age distribution (median=%.1f)'%(median_age),size=15)\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('Age',size=12)\n",
    "plt.ylabel('Number of passengers',size=12)\n",
    "\n",
    "# Add vertical median line\n",
    "plt.axvline(median_age,color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median age can be used to fill in the other data as a first stab.\n",
    "\n",
    "However, I'm interested in seeing if we can model the age instead. Let's go ahead and one-hot encode the varaibles other than age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "Survived          891 non-null int64\n",
      "Pclass            891 non-null int64\n",
      "Age               714 non-null float64\n",
      "SibSp             891 non-null int64\n",
      "Parch             891 non-null int64\n",
      "Fare              891 non-null float64\n",
      "Sex_male          891 non-null float64\n",
      "Embarked_Q        891 non-null float64\n",
      "Embarked_S        891 non-null float64\n",
      "Title_Dr          891 non-null float64\n",
      "Title_Military    891 non-null float64\n",
      "Title_Miss        891 non-null float64\n",
      "Title_Mr          891 non-null float64\n",
      "Title_Mrs         891 non-null float64\n",
      "Title_Noble       891 non-null float64\n",
      "Title_Rev         891 non-null float64\n",
      "dtypes: float64(12), int64(4)\n",
      "memory usage: 111.4 KB\n"
     ]
    }
   ],
   "source": [
    "# df['Age'].fillna(median_age,inplace=True)\n",
    "simulation_df = df.copy()\n",
    "del simulation_df['PassengerId']\n",
    "del simulation_df['Cabin']\n",
    "del simulation_df['Ticket']\n",
    "del simulation_df['Name']\n",
    "simulation_df = pd.get_dummies(simulation_df,drop_first=True)\n",
    "simulation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the data for that has values (not null) for the Age feature so we can use it to train a model that we'll use to replace the N/A values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_df = simulation_df[pd.notnull(simulation_df['Age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Military</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  \\\n",
       "0          0       3  22.0      1      0   7.2500       1.0         0.0   \n",
       "1          1       1  38.0      1      0  71.2833       0.0         0.0   \n",
       "2          1       3  26.0      0      0   7.9250       0.0         0.0   \n",
       "3          1       1  35.0      1      0  53.1000       0.0         0.0   \n",
       "4          0       3  35.0      0      0   8.0500       1.0         0.0   \n",
       "6          0       1  54.0      0      0  51.8625       1.0         0.0   \n",
       "7          0       3   2.0      3      1  21.0750       1.0         0.0   \n",
       "8          1       3  27.0      0      2  11.1333       0.0         0.0   \n",
       "9          1       2  14.0      1      0  30.0708       0.0         0.0   \n",
       "10         1       3   4.0      1      1  16.7000       0.0         0.0   \n",
       "\n",
       "    Embarked_S  Title_Dr  Title_Military  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0          1.0       0.0             0.0         0.0       1.0        0.0   \n",
       "1          0.0       0.0             0.0         0.0       0.0        1.0   \n",
       "2          1.0       0.0             0.0         1.0       0.0        0.0   \n",
       "3          1.0       0.0             0.0         0.0       0.0        1.0   \n",
       "4          1.0       0.0             0.0         0.0       1.0        0.0   \n",
       "6          1.0       0.0             0.0         0.0       1.0        0.0   \n",
       "7          1.0       0.0             0.0         0.0       0.0        0.0   \n",
       "8          1.0       0.0             0.0         0.0       0.0        1.0   \n",
       "9          0.0       0.0             0.0         0.0       0.0        1.0   \n",
       "10         1.0       0.0             0.0         1.0       0.0        0.0   \n",
       "\n",
       "    Title_Noble  Title_Rev  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "6           0.0        0.0  \n",
       "7           0.0        0.0  \n",
       "8           0.0        0.0  \n",
       "9           0.0        0.0  \n",
       "10          0.0        0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to split the data into input feature and output feature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_feature = 'Age'\n",
    "column_names = list(age_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = age_df[input_features].copy()\n",
    "y = age_df[output_feature].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform a polynomial regression using degrees 1 to 5 and use GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "pre_estimator__degree : [1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training L2 norm score:  130.719447349\n",
      "\n",
      "Test L2 norm score:  125.590523058\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'pre_estimator__degree': 1}\n",
      "\n",
      "Pipeline(steps=[('pre_estimator', PolynomialFeatures(degree=1, include_bias=True, interaction_only=False)), ('estimator', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])\n",
      "CPU times: user 557 ms, sys: 227 ms, total: 784 ms\n",
      "Wall time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "           estimator='polynomial_regression',\n",
    "           num_parameter_combos=[],\n",
    "           use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace null values with model prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for index, row in simulation_df.iterrows():\n",
    "    if pd.isnull(row[output_feature]):\n",
    "        X = row[input_features]\n",
    "        simulation_df[output_feature][index] = pipeline.predict(X.reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Military</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Survived, Pclass, Age, SibSp, Parch, Fare, Sex_male, Embarked_Q, Embarked_S, Title_Dr, Title_Military, Title_Miss, Title_Mr, Title_Mrs, Title_Noble, Title_Rev]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df[pd.isnull(simulation_df['Age'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize distributions before and after replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11503df90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAJtCAYAAABpFTf5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP+FDEzgOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1143c0f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain median Age\n",
    "median_age = simulation_df['Age'].median()\n",
    "\n",
    "# Plot a quick histogram of it:\n",
    "simulation_df['Age'].plot.hist(bins=15,color='b',figsize=(10,10))\n",
    "\n",
    "# Set title\n",
    "plt.title('Age distribution (median=%.1f)'%(median_age),size=15)\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('Age',size=12)\n",
    "plt.ylabel('Number of passengers',size=12)\n",
    "\n",
    "# Add vertical median line\n",
    "plt.axvline(median_age,color='orange')\n",
    "\n",
    "# Obtain median Age\n",
    "median_age = df['Age'].median()\n",
    "\n",
    "# Plot a quick histogram of it:\n",
    "df['Age'].plot.hist(bins=15,color='r')\n",
    "\n",
    "\n",
    "# Add vertical median line\n",
    "plt.axvline(median_age,color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifted the median just a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61616162,  0.38383838])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df['Survived'].value_counts().values/float(simulation_df['Survived'].value_counts().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null accuracy of ~62% if always predict death."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models\n",
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set output feature\n",
    "output_feature = 'Survived'\n",
    "\n",
    "# Get all column names\n",
    "column_names = list(simulation_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = simulation_df[input_features].copy()\n",
    "y = simulation_df[output_feature].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard scaling, SelectKBest, and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.831460674157\n",
      "\n",
      "Test set classification accuracy:  0.832402234637\n",
      "Confusion matrix: \n",
      "\n",
      "[[102  11]\n",
      " [ 19  47]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.5698324   0.06145251]\n",
      " [ 0.10614525  0.26256983]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       113\n",
      "          1       0.81      0.71      0.76        66\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 8, 'feature_selection__k': 15, 'estimator__weights': 'uniform'}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=15, score_func=<function f_classif at 0x119246e60>)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='uniform'))])\n",
      "CPU times: user 42.3 s, sys: 1.54 s, total: 43.9 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "           scale_type='standard',\n",
    "           feature_selection_type='select_k_best',\n",
    "           estimator='knn',\n",
    "           num_parameter_combos=[],\n",
    "           use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard scaler, SelectKBest, and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.831460674157\n",
      "\n",
      "Test set classification accuracy:  0.837988826816\n",
      "Confusion matrix: \n",
      "\n",
      "[[96 10]\n",
      " [19 54]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.53631285  0.05586592]\n",
      " [ 0.10614525  0.30167598]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87       106\n",
      "          1       0.84      0.74      0.79        73\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 15, 'estimator__C': 1.0}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=15, score_func=<function f_classif at 0x119246e60>)), ('estimator', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "CPU times: user 3.31 s, sys: 194 ms, total: 3.51 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "           scale_type='standard',\n",
    "           feature_selection_type='select_k_best',\n",
    "           estimator='logistic_regression',\n",
    "           num_parameter_combos=[],\n",
    "           use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, feature select, support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Training set classification accuracy:  0.838483146067\n",
      "\n",
      "Test set classification accuracy:  0.810055865922\n",
      "Confusion matrix: \n",
      "\n",
      "[[97 14]\n",
      " [20 48]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.54189944  0.07821229]\n",
      " [ 0.11173184  0.26815642]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85       111\n",
      "          1       0.77      0.71      0.74        68\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 13}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=13, score_func=<function f_classif at 0x119246e60>)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "CPU times: user 821 ms, sys: 88.4 ms, total: 909 ms\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "           scale_type='standard',\n",
    "           feature_selection_type='select_k_best',\n",
    "           estimator='svm',\n",
    "           num_parameter_combos=[],\n",
    "           use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, PCA, feature select, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Training set classification accuracy:  0.842696629213\n",
      "\n",
      "Test set classification accuracy:  0.793296089385\n",
      "Confusion matrix: \n",
      "\n",
      "[[102  21]\n",
      " [ 16  40]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.5698324   0.11731844]\n",
      " [ 0.08938547  0.22346369]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.83      0.85       123\n",
      "          1       0.66      0.71      0.68        56\n",
      "\n",
      "avg / total       0.80      0.79      0.80       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 9}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('feature_selection', SelectKBest(k=9, score_func=<function f_classif at 0x119246e60>))...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "CPU times: user 1.15 s, sys: 73 ms, total: 1.22 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "                                        scale_type='standard',\n",
    "                                        transform_type='pca',\n",
    "                                        feature_selection_type='select_k_best',\n",
    "                                        estimator='svm',\n",
    "                                        num_parameter_combos=[],\n",
    "                                        use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, SelectKBest, Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.834269662921\n",
      "\n",
      "Test set classification accuracy:  0.810055865922\n",
      "Confusion matrix: \n",
      "\n",
      "[[99 17]\n",
      " [17 46]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.55307263  0.09497207]\n",
      " [ 0.09497207  0.25698324]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85       116\n",
      "          1       0.73      0.73      0.73        63\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 11, 'estimator__hidden_layer_sizes': [4]}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=11, score_func=<function f_classif at 0x119246e60>)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False,...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "CPU times: user 6.82 s, sys: 350 ms, total: 7.17 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "                                        scale_type='standard', \n",
    "                                        feature_selection_type='select_k_best',\n",
    "                                        estimator='multilayer_perceptron',                                    \n",
    "                                        num_parameter_combos=70,\n",
    "                                        use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, PCA, SelectKBest, Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]\n",
      "\n",
      "Training set classification accuracy:  0.832865168539\n",
      "\n",
      "Test set classification accuracy:  0.826815642458\n",
      "Confusion matrix: \n",
      "\n",
      "[[91 13]\n",
      " [18 57]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.50837989  0.0726257 ]\n",
      " [ 0.10055866  0.31843575]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85       104\n",
      "          1       0.81      0.76      0.79        75\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 5, 'estimator__hidden_layer_sizes': [5]}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('feature_selection', SelectKBest(k=5, score_func=<function f_classif at 0x119246e60>))...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "CPU times: user 11.6 s, sys: 592 ms, total: 12.2 s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [14] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "                                        scale_type='standard', \n",
    "                                        transform_type='pca',\n",
    "                                        feature_selection_type='select_k_best',\n",
    "                                        estimator='multilayer_perceptron',                                    \n",
    "                                        num_parameter_combos=100,\n",
    "                                        use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, SelectKBest, Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.832865168539\n",
      "\n",
      "Test set classification accuracy:  0.826815642458\n",
      "Confusion matrix: \n",
      "\n",
      "[[94  7]\n",
      " [24 54]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      "[[ 0.52513966  0.03910615]\n",
      " [ 0.13407821  0.30167598]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.93      0.86       101\n",
      "          1       0.89      0.69      0.78        78\n",
      "\n",
      "avg / total       0.84      0.83      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 13, 'estimator__n_estimators': 97}\n",
      "\n",
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=13, score_func=<function f_classif at 0x119246e60>)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='a...imators=97, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "CPU times: user 2.85 s, sys: 373 ms, total: 3.22 s\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import data_science_lib\n",
    "reload(data_science_lib)\n",
    "        \n",
    "# Figure out best model\n",
    "pipeline = data_science_lib.train_model(X,y,\n",
    "                                        scale_type='standard', \n",
    "                                        feature_selection_type='select_k_best',\n",
    "                                        estimator='random_forest',                                    \n",
    "                                        num_parameter_combos=20,\n",
    "                                        use_default_param_dist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Set output feature\n",
    "output_feature = 'Survived'\n",
    "\n",
    "# Get all column names\n",
    "column_names = list(simulation_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = simulation_df[input_features].copy()\n",
    "y = simulation_df[output_feature].copy()\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Feature selection tools\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Regression tools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Unsupervised learning tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "# Cross validation tools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Form pipeline\n",
    "pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(f_classif)),         \n",
    "        ('classifier', ExtraTreesClassifier(max_depth=4,learning_rate=0.01,min_samples_split=1))\n",
    "    ])\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, {\n",
    "        'classifier__n_estimators': [300],\n",
    "        'classifier__loss' : [ 'ls', 'lad' ],\n",
    "        'feature_selection__k': range(1,len(input_features))\n",
    "#         'unsupervised__n_components': range(1,5)\n",
    "    },\n",
    "    cv=10, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Set output feature\n",
    "output_feature = 'Survived'\n",
    "\n",
    "# Get all column names\n",
    "column_names = list(simulation_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = simulation_df[input_features].copy()\n",
    "y = simulation_df[output_feature].copy()\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Feature selection tools\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Regression tools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Unsupervised learning tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "# Cross validation tools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Form pipeline\n",
    "pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(f_classif)),         \n",
    "        ('classifier', GradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, {\n",
    "        'classifier__n_estimators': [x for x in range(190,210)],\n",
    "        'feature_selection__k': range(1,len(input_features))\n",
    "#         'unsupervised__n_components': range(1,5)\n",
    "    },\n",
    "    cv=10, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one apparently can't handle a mix of binary and continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(dataframe_visualization_lib)\n",
    "dataframe_visualization_lib.continuous_pair_grid_vs_label(simulation_df,hue_feature='Survived',\n",
    "                              plot_medians=True,plot_vars=['Age','Fare'],plot_means=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete remaining fields with too much missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I delete the Cabin data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['Cabin']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classfier for survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim data for machine learning packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trimmed_df = df.copy()\n",
    "\n",
    "del trimmed_df['Name']\n",
    "del trimmed_df['Ticket']\n",
    "del trimmed_df['PassengerId']\n",
    "\n",
    "print trimmed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(trimmed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the output feature name and the input feature names and split into training and target data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_feature = 'Survived'\n",
    "column_names = list(encoded_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [column_name for column_name in column_names if column_name not in ['Survived','Sex_male','Embarked_S']]\n",
    "\n",
    "# Split into features and responses\n",
    "X = encoded_df[input_features].copy()\n",
    "y = encoded_df[output_feature].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out null accuracy baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_df['Survived'].value_counts().values/float(encoded_df['Survived'].value_counts().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most died. So a null model of always predicting death would result in a 62% null accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Form pipeline\n",
    "pipeline = Pipeline([('kbest', SelectKBest(f_classif)), ('nb', MultinomialNB())])\n",
    "\n",
    "print pipeline\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           {'kbest__k': range(1,len(input_features)),'nb__alpha': np.arange(0.0,1.0,0.1)},                           \n",
    "                           cv=10, scoring='accuracy') #,n_jobs=-1\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data then use classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# rescaled_X = StandardScaler().fit(X).transform(X)        \n",
    "\n",
    "# Pipeline([('scaler', StandardScaler()), ('clf', LinearSVC())])\n",
    "# Form pipeline \n",
    "pipeline = Pipeline([('kbest', SelectKBest(f_classif)),\n",
    "                     ('scaler', StandardScaler()), \n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# pipeline = Pipeline([('scaler', MinMaxScaler()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Normalizer()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Binarizer()), ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "print pipeline\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           {'kbest__k': range(1,len(input_features)),                            \n",
    "                            'classifier__n_neighbors': range(1,31),\n",
    "                           'classifier__weights': ['uniform','distance']},\n",
    "                           cv=10, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "# rescaled_X = StandardScaler().fit(X).transform(X)        \n",
    "\n",
    "# Pipeline([('scaler', StandardScaler()), ('clf', LinearSVC())])\n",
    "# Form pipeline \n",
    "pipeline = Pipeline([('kbest', SelectKBest(f_classif)),\n",
    "                     ('scaler', StandardScaler()), \n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "pipeline = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# pipeline = Pipeline([('scaler', MinMaxScaler()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Normalizer()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Binarizer()), ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "print pipeline\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           {'classifier__n_estimators': range(90,100)},\n",
    "                           cv=10, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "print y\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "# rescaled_X = StandardScaler().fit(X).transform(X)        \n",
    "\n",
    "# Pipeline([('scaler', StandardScaler()), ('clf', LinearSVC())])\n",
    "# Form pipeline \n",
    "# pipeline = Pipeline([('kbest', SelectKBest(f_classif)),\n",
    "#                      ('scaler', StandardScaler()), \n",
    "#                      ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# pipeline = Pipeline([('classifier', RandomForestClassifier())])\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),('classifier', MLPClassifier(solver='lbfgs',alpha=1e-5))]) #, alpha=1e-5,hidden_layer_sizes=(5, 2)\n",
    "\n",
    "\n",
    "# pipeline = Pipeline([('scaler', MinMaxScaler()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Normalizer()), ('classifier', KNeighborsClassifier())])\n",
    "# pipeline = Pipeline([('scaler', Binarizer()), ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "print pipeline\n",
    "\n",
    "# Initialize grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           {'classifier__hidden_layer_sizes': [[x] for x in range(1,100)]},\n",
    "                           cv=10, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Print grid_search parameters\n",
    "print grid_search\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Perform grid serach using above parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction based on model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out metrics and best parameters\n",
    "print 'Confusion matrix: \\n\\n',conf_mat\n",
    "\n",
    "print '\\nNormalized confusion matrix: \\n\\n',conf_mat/float(conf_mat.sum())\n",
    "\n",
    "print '\\nClassification report: \\n\\n',classification_report(y_test, y_pred)\n",
    "\n",
    "print '\\nTraining set classification accuracy: ',grid_search.best_score_\n",
    "print '\\nTest set classification accuracy: ',conf_mat.trace()/float(conf_mat.sum())\n",
    "print '\\nBest parameters:\\n'\n",
    "print grid_search.best_params_\n",
    "\n",
    "# Fit pipeline with best parameters obtained from grid search using all data\n",
    "pipeline.set_params(**grid_search.best_params_).fit(X, y)\n",
    "\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat_pipe = confusion_matrix(y_test, y_pred_pipe)\n",
    "print conf_mat_pipe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
