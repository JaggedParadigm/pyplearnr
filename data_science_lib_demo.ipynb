{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Library demo\n",
    "Here I demonstrate the data science library I developed to quickly build scikit learn pipelines with optional scaling, feature interaction, data transformation (e.g. PCA, t-SNE) steps. It runs the pipeline through a grid-search (all combinations or a specific number of them) stratified (if classification) k-folds cross-validation and outputs the best model.\n",
    "\n",
    "## Titanic dataset\n",
    "Here I use the Titanic dataset I've cleaned and pickled in a separate tutorial.\n",
    "\n",
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "Title       891 non-null object\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('trimmed_titanic_data.pkl')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By \"cleaned\" I mean I've derived titles (e.g. \"Mr.\", \"Mrs.\", \"Dr.\", etc) from the passenger names, imputed the missing Age values using polynomial regression with grid-searched 10-fold cross-validation, filled in the 3 missing Embarked values with the mode, and removed all fields that could be considered an id for that individual.\n",
    "\n",
    "Thus, there is no missing data.\n",
    "\n",
    "## Set categorical features as that type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived    891 non-null category\n",
      "Pclass      891 non-null category\n",
      "Sex         891 non-null category\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null category\n",
      "Title       891 non-null category\n",
      "dtypes: category(5), float64(2), int64(2)\n",
      "memory usage: 32.4 KB\n"
     ]
    }
   ],
   "source": [
    "simulation_df = df.copy()\n",
    "\n",
    "categorical_features = ['Survived','Pclass','Sex','Embarked','Title']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    simulation_df[feature] = simulation_df[feature].astype('category')\n",
    "    \n",
    "simulation_df.info()\n",
    "\n",
    "# df[\"A\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 17 columns):\n",
      "Age               891 non-null float64\n",
      "SibSp             891 non-null int64\n",
      "Parch             891 non-null int64\n",
      "Fare              891 non-null float64\n",
      "Survived_1        891 non-null uint8\n",
      "Pclass_2          891 non-null uint8\n",
      "Pclass_3          891 non-null uint8\n",
      "Sex_male          891 non-null uint8\n",
      "Embarked_Q        891 non-null uint8\n",
      "Embarked_S        891 non-null uint8\n",
      "Title_Dr          891 non-null uint8\n",
      "Title_Military    891 non-null uint8\n",
      "Title_Miss        891 non-null uint8\n",
      "Title_Mr          891 non-null uint8\n",
      "Title_Mrs         891 non-null uint8\n",
      "Title_Noble       891 non-null uint8\n",
      "Title_Rev         891 non-null uint8\n",
      "dtypes: float64(2), int64(2), uint8(13)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "simulation_df = pd.get_dummies(simulation_df,drop_first=True)\n",
    "\n",
    "simulation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 17 features.\n",
    "\n",
    "### Split into input/output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set output feature\n",
    "output_feature = 'Survived_1'\n",
    "\n",
    "# Get all column names\n",
    "column_names = list(simulation_df.columns)\n",
    "\n",
    "# Exclude one of every categorical variable since the other one-hot encodings cover everything\n",
    "input_features = [x for x in column_names if x != output_feature]\n",
    "\n",
    "# Split into features and responses\n",
    "X = simulation_df[input_features].copy()\n",
    "y = simulation_df[output_feature].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61616162,  0.38383838])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df['Survived_1'].value_counts().values/float(simulation_df['Survived_1'].value_counts().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, null accuracy of ~62% if always predict death.\n",
    "\n",
    "### Import data science library and initialize model collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/cmshymansky/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import data_science_lib as dsl\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic models w/ no pre-processing\n",
    "#### KNN\n",
    "Here I do a simple K-nearest neighbors (KNN) classification with 10-fold (default) cross-validation with a grid search over the default of 1 to 30 nearest neighbors and the use of either \"uniform\" or \"distance\" weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.733146067416\n",
      "\n",
      "Test set classification accuracy:  0.737430167598\n",
      "Confusion matrix: \n",
      "\n",
      " [[95 18]\n",
      " [29 37]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53072626  0.10055866]\n",
      " [ 0.16201117  0.20670391]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80       113\n",
      "          1       0.67      0.56      0.61        66\n",
      "\n",
      "avg / total       0.73      0.74      0.73       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 24, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
      "           weights='distance'))])\n",
      "CPU times: user 2.1 s, sys: 116 ms, total: 2.21 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "        \n",
    "# Figure out best model\n",
    "models['knn'] = dsl.train_model(X,y,\n",
    "                                use_default_param_dist=True,\n",
    "                                random_state=6,\n",
    "                                suppress_output=False, # Can suppress print outs if desired\n",
    "                                estimator='knn',) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that the best settings are 30 neighbors and the use of the 'distance' weight.\n",
    "\n",
    "Note how I've set the random_state to 6 so that the models can be compared using the same test/train split.\n",
    "\n",
    "The output of the train_model() method is a Pipeline object with the optimal parameters found during the grid search and trained on all data.\n",
    "\n",
    "Additional fields have been added to the pipeline object. These extra parameters are the type of score ('regression' or 'classification'), '.score_type', the training score (L2 norm for regression and classification accuracy for classification), '.train_score', the corresponding test score, '.test_score'. \n",
    "\n",
    "For classification problems, additional parameters also include the confusion matrix, '.confusion_matrix', normalized confusion matrix, '.normalized_confusion_matrix', and the classification report, '.classification_report'.\n",
    "\n",
    "Here are the outputs of these additional parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "0.733146067416\n",
      "0.737430167598\n",
      "{'estimator__n_neighbors': 24, 'estimator__weights': 'distance'}\n",
      "[[95 18]\n",
      " [29 37]]\n",
      "[[ 0.53072626  0.10055866]\n",
      " [ 0.16201117  0.20670391]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80       113\n",
      "          1       0.67      0.56      0.61        66\n",
      "\n",
      "avg / total       0.73      0.74      0.73       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = models['knn']\n",
    "\n",
    "# Score type and training/test scores\n",
    "print(pipeline.score_type)\n",
    "\n",
    "print(pipeline.train_score)\n",
    "\n",
    "print(pipeline.test_score)\n",
    "\n",
    "# Best parameters\n",
    "print(pipeline.best_parameters)\n",
    "\n",
    "# Confusion matrix, if classification\n",
    "print(pipeline.confusion_matrix) \n",
    "\n",
    "# Confusion matrix divided by its total sum\n",
    "print(pipeline.normalized_confusion_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(pipeline.classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print out from the solution above indicates that the default parameters to grid over are n_neighbors from 1 to 30 and the weights parameter as either 'uniform' or 'distance'.\n",
    "\n",
    "This can be changed in two different ways. One way is to overwrite the parameter values by setting the param_dist keyword argument with the use_default_param_dist set to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.741573033708\n",
      "\n",
      "Test set classification accuracy:  0.754189944134\n",
      "Confusion matrix: \n",
      "\n",
      " [[99 14]\n",
      " [30 36]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55307263  0.07821229]\n",
      " [ 0.16759777  0.20111732]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.88      0.82       113\n",
      "          1       0.72      0.55      0.62        66\n",
      "\n",
      "avg / total       0.75      0.75      0.75       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 73, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=73, p=2,\n",
      "           weights='distance'))])\n",
      "CPU times: user 33.9 s, sys: 1.13 s, total: 35 s\n",
      "Wall time: 51 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set custom parameters\n",
    "param_dist = {\n",
    "    'estimator__n_neighbors': range(30,500)\n",
    "}\n",
    "\n",
    "# Figure out best model\n",
    "models['custom_overwrite_knn'] = dsl.train_model(X,y,\n",
    "                                       use_default_param_dist=True,\n",
    "                                       random_state=6,\n",
    "                                       suppress_output=False, # Can suppress print outs if desired\n",
    "                                       estimator='knn',\n",
    "                                       param_dist = param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to get a slightly better accuracy doing this.\n",
    "\n",
    "The second way to use different parameter grid values is to set them with the custom param_dist keyword argument yet set use_default_param_dist to False. This makes it so that you must set every single parameter manually.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "\n",
      "Training set classification accuracy:  0.712078651685\n",
      "\n",
      "Test set classification accuracy:  0.709497206704\n",
      "Confusion matrix: \n",
      "\n",
      " [[98 15]\n",
      " [37 29]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.54748603  0.08379888]\n",
      " [ 0.20670391  0.16201117]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.87      0.79       113\n",
      "          1       0.66      0.44      0.53        66\n",
      "\n",
      "avg / total       0.70      0.71      0.69       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 43}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=43, p=2,\n",
      "           weights='uniform'))])\n",
      "CPU times: user 17.5 s, sys: 697 ms, total: 18.2 s\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set custom parameters\n",
    "param_dist = {\n",
    "    'estimator__n_neighbors': range(30,500)\n",
    "}\n",
    "\n",
    "# Figure out best model\n",
    "models['from_scratch_knn'] = dsl.train_model(X,y,\n",
    "                                       use_default_param_dist=False,\n",
    "                                       random_state=6,\n",
    "                                       suppress_output=False, # Can suppress print outs if desired\n",
    "                                       estimator='knn',\n",
    "                                       param_dist = param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the estimator__weights parameter isn't set for the KNN estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other models\n",
    "This code currently supports K-nearest neighbors, logistic regression, support vector machines, multilayer perceptrons, random forest, and adaboost. \n",
    "\n",
    "We can loop through and pick the best model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.733146067416\n",
      "\n",
      "Test set classification accuracy:  0.737430167598\n",
      "Confusion matrix: \n",
      "\n",
      " [[95 18]\n",
      " [29 37]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53072626  0.10055866]\n",
      " [ 0.16201117  0.20670391]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80       113\n",
      "          1       0.67      0.56      0.61        66\n",
      "\n",
      "avg / total       0.73      0.74      0.73       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 24, 'estimator__weights': 'distance'}\n",
      "\n",
      " Pipeline(steps=[('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
      "           weights='distance'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.720505617978\n",
      "\n",
      "Test set classification accuracy:  0.776536312849\n",
      "Confusion matrix: \n",
      "\n",
      " [[95 18]\n",
      " [22 44]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.53072626  0.10055866]\n",
      " [ 0.12290503  0.24581006]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.83       113\n",
      "          1       0.71      0.67      0.69        66\n",
      "\n",
      "avg / total       0.77      0.78      0.77       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\n",
      "\n",
      "Training set classification accuracy:  0.817415730337\n",
      "\n",
      "Test set classification accuracy:  0.877094972067\n",
      "Confusion matrix: \n",
      "\n",
      " [[106   7]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59217877  0.03910615]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       113\n",
      "          1       0.88      0.77      0.82        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [4]}\n",
      "\n",
      " Pipeline(steps=[('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=[4], learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.827247191011\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[101  12]\n",
      " [ 14  52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.56424581  0.06703911]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.89       113\n",
      "          1       0.81      0.79      0.80        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 92}\n",
      "\n",
      " Pipeline(steps=[('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=92, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.793539325843\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89       113\n",
      "          1       0.83      0.76      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 6.2 s, sys: 539 ms, total: 6.74 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models[model_name] = dsl.train_model(X,y,\n",
    "                                    use_default_param_dist=True,\n",
    "                                    random_state=6,\n",
    "                                    estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the best model is logistic regression with a classfication accuracy of ~88%.\n",
    "\n",
    "### Scaled data then classification\n",
    "We can specify the scale_type keyword argument to scale the data before being fed to the desired estimator. Currently only standard scaling is supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.823033707865\n",
      "\n",
      "Test set classification accuracy:  0.821229050279\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 23  43]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.12849162  0.24022346]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87       113\n",
      "          1       0.83      0.65      0.73        66\n",
      "\n",
      "avg / total       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 6, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[108   5]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.60335196  0.02793296]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89       113\n",
      "          1       0.90      0.68      0.78        66\n",
      "\n",
      "avg / total       0.86      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\n",
      "\n",
      "Training set classification accuracy:  0.828651685393\n",
      "\n",
      "Test set classification accuracy:  0.843575418994\n",
      "Confusion matrix: \n",
      "\n",
      " [[105   8]\n",
      " [ 20  46]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58659218  0.04469274]\n",
      " [ 0.11173184  0.25698324]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88       113\n",
      "          1       0.85      0.70      0.77        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [3]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=[3], learning_rate='constant',\n",
      "       learning_r...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.823033707865\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[100  13]\n",
      " [ 14  52]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55865922  0.0726257 ]\n",
      " [ 0.07821229  0.29050279]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       113\n",
      "          1       0.80      0.79      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 97}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=97, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.793539325843\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89       113\n",
      "          1       0.83      0.76      0.79        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 6.95 s, sys: 565 ms, total: 7.51 s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_%s'%(model_name)] = dsl.train_model(X,y,\n",
    "                                                       use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection, scaling, and classification\n",
    "The feature_selection_type keyword argument can be used to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.827247191011\n",
      "\n",
      "Test set classification accuracy:  0.815642458101\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 23  43]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.12849162  0.24022346]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.91      0.86       113\n",
      "          1       0.81      0.65      0.72        66\n",
      "\n",
      "avg / total       0.82      0.82      0.81       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 4, 'feature_selection__k': 13, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=13, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.821629213483\n",
      "\n",
      "Test set classification accuracy:  0.871508379888\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 17  49]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.09497207  0.27374302]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       113\n",
      "          1       0.89      0.74      0.81        66\n",
      "\n",
      "avg / total       0.87      0.87      0.87       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 14, 'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=14, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "\n",
      "Training set classification accuracy:  0.820224719101\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[108   5]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.60335196  0.02793296]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89       113\n",
      "          1       0.90      0.68      0.78        66\n",
      "\n",
      "avg / total       0.86      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 13}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=13, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\n",
      "\n",
      "Training set classification accuracy:  0.841292134831\n",
      "\n",
      "Test set classification accuracy:  0.832402234637\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 20  46]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.11173184  0.25698324]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87       113\n",
      "          1       0.82      0.70      0.75        66\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 16, 'estimator__hidden_layer_sizes': [8]}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=16, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False,...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.824438202247\n",
      "\n",
      "Test set classification accuracy:  0.843575418994\n",
      "Confusion matrix: \n",
      "\n",
      " [[101  12]\n",
      " [ 16  50]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.56424581  0.06703911]\n",
      " [ 0.08938547  0.27932961]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.89      0.88       113\n",
      "          1       0.81      0.76      0.78        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 12, 'estimator__n_estimators': 91}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=12, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='a...imators=91, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "feature_selection__k : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "\n",
      "Training set classification accuracy:  0.807584269663\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[103  10]\n",
      " [ 17  49]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.57541899  0.05586592]\n",
      " [ 0.09497207  0.27374302]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.88       113\n",
      "          1       0.83      0.74      0.78        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'feature_selection__k': 12}\n",
      "\n",
      " Pipeline(steps=[('feature_selection', SelectKBest(k=12, score_func=<function f_classif at 0x1144d2758>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 1min 26s, sys: 5.56 s, total: 1min 31s\n",
      "Wall time: 9min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['select_scaled_%s'%(model_name)] = dsl.train_model(X,y,\n",
    "                                                       use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       feature_selection_type = 'select_k_best', \n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score, '\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that logistic regression without scaling outperforms all combinations of scalling and the classifiers.\n",
    "\n",
    "### Scaled, transformed, then classification\n",
    "Setting the transform_type keyword argument allows the data to be transformed into a new coordinate system that is dependent on the algorithm.\n",
    "\n",
    "Currently, only principal component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE) are supported.\n",
    "\n",
    "#### PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.823033707865\n",
      "\n",
      "Test set classification accuracy:  0.821229050279\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 23  43]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.12849162  0.24022346]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87       113\n",
      "          1       0.83      0.65      0.73        66\n",
      "\n",
      "avg / total       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 6, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 100000.0}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.818820224719\n",
      "\n",
      "Test set classification accuracy:  0.854748603352\n",
      "Confusion matrix: \n",
      "\n",
      " [[108   5]\n",
      " [ 21  45]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.60335196  0.02793296]\n",
      " [ 0.11731844  0.25139665]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89       113\n",
      "          1       0.90      0.68      0.78        66\n",
      "\n",
      "avg / total       0.86      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\n",
      "\n",
      "Training set classification accuracy:  0.830056179775\n",
      "\n",
      "Test set classification accuracy:  0.871508379888\n",
      "Confusion matrix: \n",
      "\n",
      " [[108   5]\n",
      " [ 18  48]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.60335196  0.02793296]\n",
      " [ 0.10055866  0.26815642]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.90       113\n",
      "          1       0.91      0.73      0.81        66\n",
      "\n",
      "avg / total       0.88      0.87      0.87       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [4]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.804775280899\n",
      "\n",
      "Test set classification accuracy:  0.837988826816\n",
      "Confusion matrix: \n",
      "\n",
      " [[99 14]\n",
      " [15 51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.55307263  0.07821229]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87       113\n",
      "          1       0.78      0.77      0.78        66\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 96}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini...imators=96, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.816011235955\n",
      "\n",
      "Test set classification accuracy:  0.849162011173\n",
      "Confusion matrix: \n",
      "\n",
      " [[104   9]\n",
      " [ 18  48]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.58100559  0.05027933]\n",
      " [ 0.10055866  0.26815642]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.92      0.89       113\n",
      "          1       0.84      0.73      0.78        66\n",
      "\n",
      "avg / total       0.85      0.85      0.85       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('estimator', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 9.25 s, sys: 889 ms, total: 10.1 s\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_pca_%s'%(model_name)] = dsl.train_model(X,y,use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                        transform_type='pca',\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score,'\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation with PCA doesn't appear to improve our results so far.\n",
    "\n",
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__n_neighbors : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "estimator__weights : ['uniform', 'distance']\n",
      "\n",
      "Training set classification accuracy:  0.566011235955\n",
      "\n",
      "Test set classification accuracy:  0.703910614525\n",
      "Confusion matrix: \n",
      "\n",
      " [[85 28]\n",
      " [25 41]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.47486034  0.15642458]\n",
      " [ 0.1396648   0.22905028]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.75      0.76       113\n",
      "          1       0.59      0.62      0.61        66\n",
      "\n",
      "avg / total       0.71      0.70      0.71       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_neighbors': 16, 'estimator__weights': 'uniform'}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...wski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=16, p=2,\n",
      "           weights='uniform'))])\n",
      "Grid parameters:\n",
      "estimator__C : [  1.00000000e-10   1.00000000e-05   1.00000000e+00   1.00000000e+05\n",
      "   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.526685393258\n",
      "\n",
      "Test set classification accuracy:  0.659217877095\n",
      "Confusion matrix: \n",
      "\n",
      " [[75 38]\n",
      " [23 43]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.41899441  0.2122905 ]\n",
      " [ 0.12849162  0.24022346]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.66      0.71       113\n",
      "          1       0.53      0.65      0.59        66\n",
      "\n",
      "avg / total       0.68      0.66      0.66       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__C': 1e-10}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.606741573034\n",
      "\n",
      "Test set classification accuracy:  0.614525139665\n",
      "Confusion matrix: \n",
      "\n",
      " [[109   4]\n",
      " [ 65   1]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.60893855  0.02234637]\n",
      " [ 0.36312849  0.00558659]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.96      0.76       113\n",
      "          1       0.20      0.02      0.03        66\n",
      "\n",
      "avg / total       0.47      0.61      0.49       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Grid parameters:\n",
      "estimator__hidden_layer_sizes : [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]]\n",
      "\n",
      "Training set classification accuracy:  0.564606741573\n",
      "\n",
      "Test set classification accuracy:  0.664804469274\n",
      "Confusion matrix: \n",
      "\n",
      " [[79 34]\n",
      " [26 40]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.44134078  0.18994413]\n",
      " [ 0.1452514   0.22346369]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.70      0.72       113\n",
      "          1       0.54      0.61      0.57        66\n",
      "\n",
      "avg / total       0.67      0.66      0.67       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__hidden_layer_sizes': [6]}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))])\n",
      "Grid parameters:\n",
      "estimator__n_estimators : [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "\n",
      "Training set classification accuracy:  0.563202247191\n",
      "\n",
      "Test set classification accuracy:  0.642458100559\n",
      "Confusion matrix: \n",
      "\n",
      " [[97 16]\n",
      " [48 18]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.54189944  0.08938547]\n",
      " [ 0.26815642  0.10055866]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.86      0.75       113\n",
      "          1       0.53      0.27      0.36        66\n",
      "\n",
      "avg / total       0.62      0.64      0.61       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__n_estimators': 92}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...imators=92, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "Grid parameters:\n",
      "\n",
      "Training set classification accuracy:  0.558988764045\n",
      "\n",
      "Test set classification accuracy:  0.480446927374\n",
      "Confusion matrix: \n",
      "\n",
      " [[77 36]\n",
      " [57  9]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.4301676   0.20111732]\n",
      " [ 0.31843575  0.05027933]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.68      0.62       113\n",
      "          1       0.20      0.14      0.16        66\n",
      "\n",
      "avg / total       0.44      0.48      0.45       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{}\n",
      "\n",
      " Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('transform', pipeline_TSNE(angle=0.5, early_exaggeration=4.0, init='pca',\n",
      "       learning_rate=1000.0, method='barnes_hut', metric='euclidean',\n",
      "       min_grad_norm=1e-07, n_components=2, n_iter=1000,\n",
      "       n_iter_without...m='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "CPU times: user 1min 6s, sys: 7.87 s, total: 1min 14s\n",
      "Wall time: 23min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "\n",
    "# Set model names to iterate over\n",
    "model_names = ['knn','logistic_regression','svm','multilayer_perceptron','random_forest','adaboost']        \n",
    "\n",
    "# Cross-validate each model\n",
    "for model_name in model_names:\n",
    "    models['scaled_t-sne_%s'%(model_name)] = dsl.train_model(X,y,use_default_param_dist=True,\n",
    "                                                       random_state=6,\n",
    "                                                        transform_type='t-sne',\n",
    "                                                       scale_type = 'standard',\n",
    "                                                       estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression 0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_names = models.keys()\n",
    "\n",
    "model_scores = [models[model].test_score for model in trained_model_names]\n",
    "\n",
    "max_score = max(model_scores)\n",
    "\n",
    "best_model = trained_model_names[model_scores.index(max_score)]\n",
    "\n",
    "print best_model,max_score,'\\n\\n',models[best_model].classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with with scaling and selection appears to outperform all other scenarios so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the best model's properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: logistic_regression \n",
      "\n",
      "Training score:\t\t0.818820224719\n",
      "Test score:\t\t0.882681564246 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[107   6]\n",
      " [ 15  51]] \n",
      "\n",
      "Normalized confusion matrix:\n",
      "\n",
      "[[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]] \n",
      "\n",
      "Best parameters:\n",
      "{'estimator__C': 100000.0}\n"
     ]
    }
   ],
   "source": [
    "print 'Best model:','logistic_regression','\\n'\n",
    "print 'Training score:\\t\\t', models['logistic_regression'].train_score\n",
    "print 'Test score:\\t\\t', models['logistic_regression'].test_score,'\\n'\n",
    "print models['logistic_regression'].classification_report\n",
    "\n",
    "print 'Confusion matrix:\\n\\n',models['logistic_regression'].confusion_matrix,'\\n'\n",
    "print 'Normalized confusion matrix:\\n\\n',models['logistic_regression'].normalized_confusion_matrix,'\\n'\n",
    "print 'Best parameters:\\n', models['logistic_regression'].best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_predict_proba_lr',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'dual',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'intercept_scaling',\n",
       " 'max_iter',\n",
       " 'multi_class',\n",
       " 'n_iter_',\n",
       " 'n_jobs',\n",
       " 'penalty',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'solver',\n",
       " 'sparsify',\n",
       " 'tol',\n",
       " 'transform',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models['logistic_regression'].steps[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-10,   1.59228279e-10,   2.53536449e-10,\n",
       "         4.03701726e-10,   6.42807312e-10,   1.02353102e-09,\n",
       "         1.62975083e-09,   2.59502421e-09,   4.13201240e-09,\n",
       "         6.57933225e-09,   1.04761575e-08,   1.66810054e-08,\n",
       "         2.65608778e-08,   4.22924287e-08,   6.73415066e-08,\n",
       "         1.07226722e-07,   1.70735265e-07,   2.71858824e-07,\n",
       "         4.32876128e-07,   6.89261210e-07,   1.09749877e-06,\n",
       "         1.74752840e-06,   2.78255940e-06,   4.43062146e-06,\n",
       "         7.05480231e-06,   1.12332403e-05,   1.78864953e-05,\n",
       "         2.84803587e-05,   4.53487851e-05,   7.22080902e-05,\n",
       "         1.14975700e-04,   1.83073828e-04,   2.91505306e-04,\n",
       "         4.64158883e-04,   7.39072203e-04,   1.17681195e-03,\n",
       "         1.87381742e-03,   2.98364724e-03,   4.75081016e-03,\n",
       "         7.56463328e-03,   1.20450354e-02,   1.91791026e-02,\n",
       "         3.05385551e-02,   4.86260158e-02,   7.74263683e-02,\n",
       "         1.23284674e-01,   1.96304065e-01,   3.12571585e-01,\n",
       "         4.97702356e-01,   7.92482898e-01,   1.26185688e+00,\n",
       "         2.00923300e+00,   3.19926714e+00,   5.09413801e+00,\n",
       "         8.11130831e+00,   1.29154967e+01,   2.05651231e+01,\n",
       "         3.27454916e+01,   5.21400829e+01,   8.30217568e+01,\n",
       "         1.32194115e+02,   2.10490414e+02,   3.35160265e+02,\n",
       "         5.33669923e+02,   8.49753436e+02,   1.35304777e+03,\n",
       "         2.15443469e+03,   3.43046929e+03,   5.46227722e+03,\n",
       "         8.69749003e+03,   1.38488637e+04,   2.20513074e+04,\n",
       "         3.51119173e+04,   5.59081018e+04,   8.90215085e+04,\n",
       "         1.41747416e+05,   2.25701972e+05,   3.59381366e+05,\n",
       "         5.72236766e+05,   9.11162756e+05,   1.45082878e+06,\n",
       "         2.31012970e+06,   3.67837977e+06,   5.85702082e+06,\n",
       "         9.32603347e+06,   1.48496826e+07,   2.36448941e+07,\n",
       "         3.76493581e+07,   5.99484250e+07,   9.54548457e+07,\n",
       "         1.51991108e+08,   2.42012826e+08,   3.85352859e+08,\n",
       "         6.13590727e+08,   9.77009957e+08,   1.55567614e+09,\n",
       "         2.47707636e+09,   3.94420606e+09,   6.28029144e+09,\n",
       "         1.00000000e+10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.logspace(-10,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid parameters:\n",
      "estimator__penalty : ['l2', 'l1']\n",
      "estimator__C : [  1.00000000e-10   1.59228279e-10   2.53536449e-10   4.03701726e-10\n",
      "   6.42807312e-10   1.02353102e-09   1.62975083e-09   2.59502421e-09\n",
      "   4.13201240e-09   6.57933225e-09   1.04761575e-08   1.66810054e-08\n",
      "   2.65608778e-08   4.22924287e-08   6.73415066e-08   1.07226722e-07\n",
      "   1.70735265e-07   2.71858824e-07   4.32876128e-07   6.89261210e-07\n",
      "   1.09749877e-06   1.74752840e-06   2.78255940e-06   4.43062146e-06\n",
      "   7.05480231e-06   1.12332403e-05   1.78864953e-05   2.84803587e-05\n",
      "   4.53487851e-05   7.22080902e-05   1.14975700e-04   1.83073828e-04\n",
      "   2.91505306e-04   4.64158883e-04   7.39072203e-04   1.17681195e-03\n",
      "   1.87381742e-03   2.98364724e-03   4.75081016e-03   7.56463328e-03\n",
      "   1.20450354e-02   1.91791026e-02   3.05385551e-02   4.86260158e-02\n",
      "   7.74263683e-02   1.23284674e-01   1.96304065e-01   3.12571585e-01\n",
      "   4.97702356e-01   7.92482898e-01   1.26185688e+00   2.00923300e+00\n",
      "   3.19926714e+00   5.09413801e+00   8.11130831e+00   1.29154967e+01\n",
      "   2.05651231e+01   3.27454916e+01   5.21400829e+01   8.30217568e+01\n",
      "   1.32194115e+02   2.10490414e+02   3.35160265e+02   5.33669923e+02\n",
      "   8.49753436e+02   1.35304777e+03   2.15443469e+03   3.43046929e+03\n",
      "   5.46227722e+03   8.69749003e+03   1.38488637e+04   2.20513074e+04\n",
      "   3.51119173e+04   5.59081018e+04   8.90215085e+04   1.41747416e+05\n",
      "   2.25701972e+05   3.59381366e+05   5.72236766e+05   9.11162756e+05\n",
      "   1.45082878e+06   2.31012970e+06   3.67837977e+06   5.85702082e+06\n",
      "   9.32603347e+06   1.48496826e+07   2.36448941e+07   3.76493581e+07\n",
      "   5.99484250e+07   9.54548457e+07   1.51991108e+08   2.42012826e+08\n",
      "   3.85352859e+08   6.13590727e+08   9.77009957e+08   1.55567614e+09\n",
      "   2.47707636e+09   3.94420606e+09   6.28029144e+09   1.00000000e+10]\n",
      "\n",
      "Training set classification accuracy:  0.821629213483\n",
      "\n",
      "Test set classification accuracy:  0.882681564246\n",
      "Confusion matrix: \n",
      "\n",
      " [[107   6]\n",
      " [ 15  51]]\n",
      "\n",
      "Normalized confusion matrix: \n",
      "\n",
      " [[ 0.59776536  0.03351955]\n",
      " [ 0.08379888  0.2849162 ]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       113\n",
      "          1       0.89      0.77      0.83        66\n",
      "\n",
      "avg / total       0.88      0.88      0.88       179\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "\n",
      "{'estimator__penalty': 'l2', 'estimator__C': 32.745491628777316}\n",
      "\n",
      " Pipeline(steps=[('estimator', LogisticRegression(C=32.745491628777316, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "CPU times: user 7.47 s, sys: 439 ms, total: 7.91 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "reload(dsl)\n",
    "        \n",
    "param_dist = {\n",
    "    'estimator__C': np.logspace(-10,10,100),\n",
    "    'estimator__penalty': ['l2','l1']\n",
    "}\n",
    "    \n",
    "# Figure out best model\n",
    "models['custom_logistic_regression'] = dsl.train_model(X,y,\n",
    "                                use_default_param_dist=True,\n",
    "                                random_state=6,\n",
    "                                suppress_output=False, # Can suppress print outs if desired\n",
    "                                estimator='logistic_regression',\n",
    "                               param_dist=param_dist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age \t-0.0393259488071\n",
      "SibSp \t-0.574788721716\n",
      "Parch \t-0.356123712301\n",
      "Fare \t0.00342610855198\n",
      "Pclass_2 \t-1.16243960759\n",
      "Pclass_3 \t-2.32359915558\n",
      "Sex_male \t-2.08805882672\n",
      "Embarked_Q \t0.0140621138536\n",
      "Embarked_S \t-0.358487135498\n",
      "Title_Dr \t-2.58436225926\n",
      "Title_Military \t-2.20878843244\n",
      "Title_Miss \t-2.35635331024\n",
      "Title_Mr \t-3.05281011203\n",
      "Title_Mrs \t-1.35803888823\n",
      "Title_Noble \t-2.70897267991\n",
      "Title_Rev \t-4.92165404335\n"
     ]
    }
   ],
   "source": [
    "model_coefficients = models['custom_logistic_regression'].steps[0][1].coef_[0]\n",
    "\n",
    "feature_ind = 0\n",
    "indices = []\n",
    "for feature in simulation_df.columns:\n",
    "    if feature != 'Survived_1':\n",
    "        print feature, '\\t',model_coefficients[feature_ind]\n",
    "        \n",
    "        feature_ind += 1\n",
    "        \n",
    "model_df = pd.Series(model_coefficients,index=[feature for feature in simulation_df.columns if feature != 'Survived_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select_scaled_random_forest',\n",
       " 'select_scaled_logistic_regression',\n",
       " 'scaled_t-sne_logistic_regression',\n",
       " 'scaled_pca_adaboost',\n",
       " 'logistic_regression',\n",
       " 'custom_logistic_regression',\n",
       " 'scaled_t-sne_multilayer_perceptron',\n",
       " 'scaled_random_forest',\n",
       " 'scaled_knn',\n",
       " 'scaled_pca_svm',\n",
       " 'scaled_pca_random_forest',\n",
       " 'scaled_t-sne_knn',\n",
       " 'custom_overwrite_knn',\n",
       " 'multilayer_perceptron',\n",
       " 'scaled_t-sne_svm',\n",
       " 'scaled_adaboost',\n",
       " 'scaled_pca_logistic_regression',\n",
       " 'select_scaled_adaboost',\n",
       " 'select_scaled_svm',\n",
       " 'select_scaled_knn',\n",
       " 'scaled_t-sne_adaboost',\n",
       " 'scaled_pca_multilayer_perceptron',\n",
       " 'scaled_logistic_regression',\n",
       " 'knn',\n",
       " 'svm',\n",
       " 'from_scratch_knn',\n",
       " 'scaled_svm',\n",
       " 'select_scaled_multilayer_perceptron',\n",
       " 'scaled_t-sne_random_forest',\n",
       " 'adaboost',\n",
       " 'random_forest',\n",
       " 'scaled_multilayer_perceptron',\n",
       " 'scaled_pca_knn']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title_Rev        -4.921654\n",
       "Title_Mr         -3.052810\n",
       "Title_Noble      -2.708973\n",
       "Title_Dr         -2.584362\n",
       "Title_Miss       -2.356353\n",
       "Pclass_3         -2.323599\n",
       "Title_Military   -2.208788\n",
       "Sex_male         -2.088059\n",
       "Title_Mrs        -1.358039\n",
       "Pclass_2         -1.162440\n",
       "SibSp            -0.574789\n",
       "Embarked_S       -0.358487\n",
       "Parch            -0.356124\n",
       "Age              -0.039326\n",
       "Fare              0.003426\n",
       "Embarked_Q        0.014062\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like being a Reverend had a very negative effect on survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    3\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'][df['Title']=='Dr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were six reverends and all died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next worst was having the title of \"Mr\". This is in contrast to just generally being a male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>C</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>C</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>C</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Title\n",
       "30          0       1    male  40.0      0      0  27.7208        C  Noble\n",
       "556         1       1  female  48.0      1      0  39.6000        C  Noble\n",
       "599         1       1    male  49.0      1      0  56.9292        C  Noble\n",
       "759         1       1  female  33.0      0      0  86.5000        S  Noble\n",
       "822         0       1    male  38.0      0      0   0.0000        S  Noble"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Title']=='Noble']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>C</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.248543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>-10.035641</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.991400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>C</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.248543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>C</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>C</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Sex        Age  SibSp  Parch      Fare Embarked  \\\n",
       "7           0       3  male   2.000000      3      1   21.0750        S   \n",
       "16          0       3  male   2.000000      4      1   29.1250        Q   \n",
       "30          0       1  male  40.000000      0      0   27.7208        C   \n",
       "50          0       3  male   7.000000      4      1   39.6875        S   \n",
       "59          0       3  male  11.000000      5      2   46.9000        S   \n",
       "63          0       3  male   4.000000      3      2   27.9000        S   \n",
       "65          1       3  male   1.248543      1      1   15.2458        C   \n",
       "78          1       2  male   0.830000      0      2   29.0000        S   \n",
       "125         1       3  male  12.000000      1      0   11.2417        C   \n",
       "159         0       3  male -10.035641      8      2   69.5500        S   \n",
       "164         0       3  male   1.000000      4      1   39.6875        S   \n",
       "165         1       3  male   9.000000      0      2   20.5250        S   \n",
       "171         0       3  male   4.000000      4      1   29.1250        Q   \n",
       "176         0       3  male   1.991400      3      1   25.4667        S   \n",
       "182         0       3  male   9.000000      4      2   31.3875        S   \n",
       "183         1       2  male   1.000000      2      1   39.0000        S   \n",
       "193         1       2  male   3.000000      1      1   26.0000        S   \n",
       "261         1       3  male   3.000000      4      2   31.3875        S   \n",
       "278         0       3  male   7.000000      4      1   29.1250        Q   \n",
       "305         1       1  male   0.920000      1      2  151.5500        S   \n",
       "340         1       2  male   2.000000      1      1   26.0000        S   \n",
       "348         1       3  male   3.000000      1      1   15.9000        S   \n",
       "386         0       3  male   1.000000      5      2   46.9000        S   \n",
       "407         1       2  male   3.000000      1      1   18.7500        S   \n",
       "445         1       1  male   4.000000      0      2   81.8583        S   \n",
       "449         1       1  male  52.000000      0      0   30.5000        S   \n",
       "480         0       3  male   9.000000      5      2   46.9000        S   \n",
       "489         1       3  male   9.000000      1      1   15.9000        S   \n",
       "536         0       1  male  45.000000      0      0   26.5500        S   \n",
       "549         1       2  male   8.000000      1      1   36.7500        S   \n",
       "599         1       1  male  49.000000      1      0   56.9292        C   \n",
       "647         1       1  male  56.000000      0      0   35.5000        C   \n",
       "694         0       1  male  60.000000      0      0   26.5500        S   \n",
       "709         1       3  male   1.248543      1      1   15.2458        C   \n",
       "745         0       1  male  70.000000      1      1   71.0000        S   \n",
       "751         1       3  male   6.000000      0      1   12.4750        S   \n",
       "755         1       2  male   0.670000      1      1   14.5000        S   \n",
       "787         0       3  male   8.000000      4      1   29.1250        Q   \n",
       "788         1       3  male   1.000000      1      2   20.5750        S   \n",
       "802         1       1  male  11.000000      1      2  120.0000        S   \n",
       "803         1       3  male   0.420000      0      1    8.5167        C   \n",
       "819         0       3  male  10.000000      3      2   27.9000        S   \n",
       "822         0       1  male  38.000000      0      0    0.0000        S   \n",
       "824         0       3  male   2.000000      4      1   39.6875        S   \n",
       "827         1       2  male   1.000000      0      2   37.0042        C   \n",
       "831         1       2  male   0.830000      1      1   18.7500        S   \n",
       "850         0       3  male   4.000000      4      2   31.2750        S   \n",
       "869         1       3  male   4.000000      1      1   11.1333        S   \n",
       "\n",
       "        Title  \n",
       "7       Child  \n",
       "16      Child  \n",
       "30      Noble  \n",
       "50      Child  \n",
       "59      Child  \n",
       "63      Child  \n",
       "65      Child  \n",
       "78      Child  \n",
       "125     Child  \n",
       "159     Child  \n",
       "164     Child  \n",
       "165     Child  \n",
       "171     Child  \n",
       "176     Child  \n",
       "182     Child  \n",
       "183     Child  \n",
       "193     Child  \n",
       "261     Child  \n",
       "278     Child  \n",
       "305     Child  \n",
       "340     Child  \n",
       "348     Child  \n",
       "386     Child  \n",
       "407     Child  \n",
       "445     Child  \n",
       "449  Military  \n",
       "480     Child  \n",
       "489     Child  \n",
       "536  Military  \n",
       "549     Child  \n",
       "599     Noble  \n",
       "647  Military  \n",
       "694  Military  \n",
       "709     Child  \n",
       "745  Military  \n",
       "751     Child  \n",
       "755     Child  \n",
       "787     Child  \n",
       "788     Child  \n",
       "802     Child  \n",
       "803     Child  \n",
       "819     Child  \n",
       "822     Noble  \n",
       "824     Child  \n",
       "827     Child  \n",
       "831     Child  \n",
       "850     Child  \n",
       "869     Child  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Sex']=='male')&(~df['Title'].isin(['Mr','Dr','Rev']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Military</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch   Fare  Survived_1  Pclass_2  Pclass_3  Sex_male  \\\n",
       "449  52.0      0      0  30.50           1         0         0         1   \n",
       "536  45.0      0      0  26.55           0         0         0         1   \n",
       "647  56.0      0      0  35.50           1         0         0         1   \n",
       "694  60.0      0      0  26.55           0         0         0         1   \n",
       "745  70.0      1      1  71.00           0         0         0         1   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Title_Dr  Title_Military  Title_Miss  Title_Mr  \\\n",
       "449           0           1         0               1           0         0   \n",
       "536           0           1         0               1           0         0   \n",
       "647           0           0         0               1           0         0   \n",
       "694           0           1         0               1           0         0   \n",
       "745           0           1         0               1           0         0   \n",
       "\n",
       "     Title_Mrs  Title_Noble  Title_Rev  \n",
       "449          0            0          0  \n",
       "536          0            0          0  \n",
       "647          0            0          0  \n",
       "694          0            0          0  \n",
       "745          0            0          0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df[simulation_df['Title_Military']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(891, 16)\n"
     ]
    }
   ],
   "source": [
    "print models['select_scaled_logistic_regression'].steps[2][1].coef_[0].shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age \t-0.614482601163\n",
      "SibSp \t-0.612587885195\n",
      "Parch \t-0.283176325042\n",
      "Fare \t0.168724602965\n",
      "Pclass_2 \t-0.461866528278\n",
      "Pclass_3 \t-1.15687512926\n",
      "Sex_male \t-4.11242073907\n",
      "Embarked_S \t-0.173196484322\n",
      "Title_Dr \t-0.209834891899\n",
      "Title_Miss \t-3.48708462491\n",
      "Title_Mr \t-1.32195791696\n",
      "Title_Mrs \t-2.6056826261\n",
      "Title_Noble \t-0.208062438608\n",
      "Title_Rev \t-0.957725925523\n"
     ]
    }
   ],
   "source": [
    "feature_mask = models['select_scaled_logistic_regression'].steps[0][1].get_support()\n",
    "input_features = [feature for feature in simulation_df.columns if feature != 'Survived_1']\n",
    "\n",
    "model_coefficients = models['select_scaled_logistic_regression'].steps[2][1].coef_[0]\n",
    "\n",
    "feature_ind = 0\n",
    "for feature in np.array(input_features)[feature_mask]:\n",
    "    print feature, '\\t',model_coefficients[feature_ind]\n",
    "        \n",
    "    feature_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.614482601163\n",
      "-0.612587885195\n",
      "-0.283176325042\n",
      "0.168724602965\n",
      "-0.461866528278\n",
      "-1.15687512926\n",
      "-4.11242073907\n",
      "-0.173196484322\n",
      "-0.209834891899\n",
      "-3.48708462491\n",
      "-1.32195791696\n",
      "-2.6056826261\n",
      "-0.208062438608\n",
      "-0.957725925523\n",
      "Index([u'Age', u'SibSp', u'Parch', u'Fare', u'Survived_1', u'Pclass_2',\n",
      "       u'Pclass_3', u'Sex_male', u'Embarked_Q', u'Embarked_S', u'Title_Dr',\n",
      "       u'Title_Military', u'Title_Miss', u'Title_Mr', u'Title_Mrs',\n",
      "       u'Title_Noble', u'Title_Rev'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for x in models['select_scaled_logistic_regression'].steps[2][1].coef_[0]:\n",
    "    print x\n",
    "\n",
    "print simulation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age \t-0.614482601163\n",
      "SibSp \t-0.612587885195\n",
      "Parch \t-0.283176325042\n",
      "Fare \t0.168724602965\n",
      "Pclass_2 \t-0.461866528278\n",
      "Pclass_3 \t-1.15687512926\n",
      "Sex_male \t-4.11242073907\n",
      "Embarked_Q \t-0.173196484322\n",
      "Embarked_S \t-0.209834891899\n",
      "Title_Dr \t-3.48708462491\n",
      "Title_Military \t-1.32195791696\n",
      "Title_Miss \t-2.6056826261\n",
      "Title_Mr \t-0.208062438608\n",
      "Title_Mrs \t-0.957725925523\n",
      "Title_Noble \t"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7f7e741cb45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimulation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Survived_1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_coefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfeature_ind\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 14"
     ]
    }
   ],
   "source": [
    "model_coefficients = models['select_scaled_logistic_regression'].steps[2][1].coef_[0]\n",
    "\n",
    "feature_ind = 0\n",
    "for feature in simulation_df.columns:\n",
    "    if feature != 'Survived_1': \n",
    "        print feature, '\\t',model_coefficients[feature_ind]\n",
    "        \n",
    "        feature_ind += 1\n",
    "        \n",
    "print model_coefficients[feature_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Military</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>45.062712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  SibSp  Parch      Fare  Survived_1  Pclass_2  Pclass_3  \\\n",
       "245  44.000000      2      0   90.0000           0         0         0   \n",
       "317  54.000000      0      0   14.0000           0         1         0   \n",
       "398  23.000000      0      0   10.5000           0         1         0   \n",
       "632  32.000000      0      0   30.5000           1         0         0   \n",
       "660  50.000000      2      0  133.6500           1         0         0   \n",
       "766  45.062712      0      0   39.6000           0         0         0   \n",
       "796  49.000000      0      0   25.9292           1         0         0   \n",
       "\n",
       "     Sex_male  Embarked_Q  Embarked_S  Title_Dr  Title_Military  Title_Miss  \\\n",
       "245         1           1           0         1               0           0   \n",
       "317         1           0           1         1               0           0   \n",
       "398         1           0           1         1               0           0   \n",
       "632         1           0           0         1               0           0   \n",
       "660         1           0           1         1               0           0   \n",
       "766         1           0           0         1               0           0   \n",
       "796         0           0           1         1               0           0   \n",
       "\n",
       "     Title_Mr  Title_Mrs  Title_Noble  Title_Rev  \n",
       "245         0          0            0          0  \n",
       "317         0          0            0          0  \n",
       "398         0          0            0          0  \n",
       "632         0          0            0          0  \n",
       "660         0          0            0          0  \n",
       "766         0          0            0          0  \n",
       "796         0          0            0          0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df[simulation_df['Title_Dr']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
